{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Bitcoin Prices using twitter sentiment  and time series data\n",
    "\n",
    "In this project we are going to predict the prices of Bitcoin using deep learning. We will use two type of data. One will be simple numerci data as we did in our last project. Other will be sentiments from twitter tweets. As we know that not only numeric data can drive prices but the human speculation also can drive the prices. So we will combine them both and will see how the overall model perfomrms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2018-02-27 00:00:00')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('sentiment_full.csv')\n",
    "#df['Date']=pd.to_datetime(['Date'],format=\"[datetime.date(%Y,%m,%d)]\")\n",
    "#print(df['Date'][1])\n",
    "i = data['Date'].astype(str)\\\n",
    "      .str.findall('\\d+')\\\n",
    "      .str.join('/')\n",
    "data['Date'] = pd.to_datetime(i, errors='coerce')\n",
    "data['Date'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will fetch bitcoin data from coinmarkte cap website as we did in our last work. The official site is here https://coinmarketcap.com/currencies/bitcoin/ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Market Cap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-03-14</td>\n",
       "      <td>8269.81</td>\n",
       "      <td>9214.65</td>\n",
       "      <td>9355.85</td>\n",
       "      <td>8068.59</td>\n",
       "      <td>6438230000</td>\n",
       "      <td>155891000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-03-13</td>\n",
       "      <td>9194.85</td>\n",
       "      <td>9173.04</td>\n",
       "      <td>9470.38</td>\n",
       "      <td>8958.19</td>\n",
       "      <td>5991140000</td>\n",
       "      <td>155168000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-03-12</td>\n",
       "      <td>9205.12</td>\n",
       "      <td>9602.93</td>\n",
       "      <td>9937.50</td>\n",
       "      <td>8956.43</td>\n",
       "      <td>6457400000</td>\n",
       "      <td>162421000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-03-11</td>\n",
       "      <td>9578.63</td>\n",
       "      <td>8852.78</td>\n",
       "      <td>9711.89</td>\n",
       "      <td>8607.12</td>\n",
       "      <td>6296370000</td>\n",
       "      <td>149716000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-03-10</td>\n",
       "      <td>8866.00</td>\n",
       "      <td>9350.59</td>\n",
       "      <td>9531.32</td>\n",
       "      <td>8828.47</td>\n",
       "      <td>5386320000</td>\n",
       "      <td>158119000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date    Close     Open     High      Low      Volume    Market Cap\n",
       "0 2018-03-14  8269.81  9214.65  9355.85  8068.59  6438230000  155891000000\n",
       "1 2018-03-13  9194.85  9173.04  9470.38  8958.19  5991140000  155168000000\n",
       "2 2018-03-12  9205.12  9602.93  9937.50  8956.43  6457400000  162421000000\n",
       "3 2018-03-11  9578.63  8852.78  9711.89  8607.12  6296370000  149716000000\n",
       "4 2018-03-10  8866.00  9350.59  9531.32  8828.47  5386320000  158119000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get market info for bitcoin from the start of 2016 to the current day\n",
    "bitcoin_market_info = pd.read_html(\"https://coinmarketcap.com/currencies/bitcoin/historical-data/?start=20130428&end=\"+time.strftime(\"%Y%m%d\"))[0]\n",
    "# convert the date string to the correct date format\n",
    "bitcoin_market_info = bitcoin_market_info.assign(Date=pd.to_datetime(bitcoin_market_info['Date']))\n",
    "# when Volume is equal to '-' convert it to 0\n",
    "bitcoin_market_info.loc[bitcoin_market_info['Volume']==\"-\",'Volume']=0\n",
    "# convert to int\n",
    "bitcoin_market_info['Volume'] = bitcoin_market_info['Volume'].astype('int64')\n",
    "# look at the first few rows\n",
    "bitcoin_market_info=bitcoin_market_info[['Date','Close','Open','High','Low','Volume','Market Cap']]\n",
    "#bitcoin_market_info.rename(columns={\"Date\":\"Time\"},inplace=True)\n",
    "bitcoin_market_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have twitter data fetched using twitter API. We have analyzed the sentiments using textblob library. All the files are on Github repository so you can clone them and use them as per your need. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are loading the previously separately trained models on numeric data and sentiment data. We will see how they alone performs on making predictions and then we will combine them for better performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model1 = load_model('close_price_lstm.h5')\n",
    "model2=load_model('sentiment_price.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use numeric data for making predictions. As the model has been trained on all the data available in the market. It gives us good results.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_data=np.array([[10725.60,10393.90,10878.50,10246.10,6966180000,175536000000],\n",
    "                      [10366.70,9669.43,10475.00,9501.73,7287690000,163283000000],\n",
    "                      [9664.73,9796.42,9923.22,9407.06,5706940000,165407000000],\n",
    "                      [9813.07,10287.70,10597.20,9546.97,6917930000,173682000000],\n",
    "                      [10301.10,9937.07,10487.30,9734.56,7739500000,167746000000],\n",
    "                      [10005.00,10660.40,11039.10,9939.09,8040080000,179936000000]])\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "a=scaler.fit_transform(predict_data)\n",
    "pre=model1.predict(a.reshape(predict_data.shape[0],1,6))\n",
    "phat=np.concatenate((pre,a[:,1:]),axis=1)\n",
    "#print(phat)\n",
    "predicted=scaler.inverse_transform(phat)\n",
    "#print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date  real_close  predicted_close  Difference  Percentage_change\n",
      "0 2018-02-28    10397.90     10491.695183   93.795183           0.893995\n",
      "1 2018-02-27    10725.60      9997.942656  727.657344           7.278071\n",
      "2 2018-02-26    10366.70      9703.386253  663.313747           6.835900\n",
      "3 2018-02-25     9664.73     10050.264651  385.534651           3.836065\n",
      "4 2018-02-24     9813.07     10110.501936  297.431936           2.941812\n",
      "5 2018-02-23    10301.10     10349.661903   48.561903           0.469212\n"
     ]
    }
   ],
   "source": [
    "real_close=[10397.90,10725.60,10366.70,9664.73,9813.07,10301.10]\n",
    "predicted_close=[]\n",
    "date=[]\n",
    "difference=[]\n",
    "pr_change=[]\n",
    "date=pd.date_range('02-23-2018','02-28-2018',freq='D').sort_values(ascending=False)\n",
    "#print(date)\n",
    "for i in range(predict_data.shape[0]):\n",
    "    predicted_close.append(predicted[i,0])\n",
    "    difference.append(abs(predicted[i,0]-real_close[i]))\n",
    "    pr_change.append((abs(predicted[i,0]-real_close[i])/predicted[i,0])*100)\n",
    "df=pd.DataFrame({'Date':date})\n",
    "df['real_close']=real_close\n",
    "df['predicted_close']=predicted_close\n",
    "df['Difference']=difference\n",
    "df['Percentage_change']=pr_change\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above simple predictions we can see that our model is perfomring really well on making predictions for future prices. The simple reason is that the data is highly corelated with each other. Model get lot of information from it to learn the hidden pattern from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will load the dataframe which has both sentiment scores and numeric data of the close prices of Bitcoin. We will use first 8 rows of the data to make prediction later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Market Cap</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-02-28</td>\n",
       "      <td>10397.90</td>\n",
       "      <td>10687.20</td>\n",
       "      <td>11089.80</td>\n",
       "      <td>10393.10</td>\n",
       "      <td>6936190000</td>\n",
       "      <td>180510000000</td>\n",
       "      <td>0.070307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-02-27</td>\n",
       "      <td>10725.60</td>\n",
       "      <td>10393.90</td>\n",
       "      <td>10878.50</td>\n",
       "      <td>10246.10</td>\n",
       "      <td>6966180000</td>\n",
       "      <td>175536000000</td>\n",
       "      <td>0.059455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-02-26</td>\n",
       "      <td>10366.70</td>\n",
       "      <td>9669.43</td>\n",
       "      <td>10475.00</td>\n",
       "      <td>9501.73</td>\n",
       "      <td>7287690000</td>\n",
       "      <td>163283000000</td>\n",
       "      <td>0.059455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-02-25</td>\n",
       "      <td>9664.73</td>\n",
       "      <td>9796.42</td>\n",
       "      <td>9923.22</td>\n",
       "      <td>9407.06</td>\n",
       "      <td>5706940000</td>\n",
       "      <td>165407000000</td>\n",
       "      <td>0.059455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-02-24</td>\n",
       "      <td>9813.07</td>\n",
       "      <td>10287.70</td>\n",
       "      <td>10597.20</td>\n",
       "      <td>9546.97</td>\n",
       "      <td>6917930000</td>\n",
       "      <td>173682000000</td>\n",
       "      <td>0.059455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-02-23</td>\n",
       "      <td>10301.10</td>\n",
       "      <td>9937.07</td>\n",
       "      <td>10487.30</td>\n",
       "      <td>9734.56</td>\n",
       "      <td>7739500000</td>\n",
       "      <td>167746000000</td>\n",
       "      <td>0.059455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-02-22</td>\n",
       "      <td>10005.00</td>\n",
       "      <td>10660.40</td>\n",
       "      <td>11039.10</td>\n",
       "      <td>9939.09</td>\n",
       "      <td>8040080000</td>\n",
       "      <td>179936000000</td>\n",
       "      <td>0.059455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-02-21</td>\n",
       "      <td>10690.40</td>\n",
       "      <td>11372.20</td>\n",
       "      <td>11418.50</td>\n",
       "      <td>10479.10</td>\n",
       "      <td>9405340000</td>\n",
       "      <td>191927000000</td>\n",
       "      <td>0.110849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date     Close      Open      High       Low      Volume  \\\n",
       "0  2018-02-28  10397.90  10687.20  11089.80  10393.10  6936190000   \n",
       "1  2018-02-27  10725.60  10393.90  10878.50  10246.10  6966180000   \n",
       "2  2018-02-26  10366.70   9669.43  10475.00   9501.73  7287690000   \n",
       "3  2018-02-25   9664.73   9796.42   9923.22   9407.06  5706940000   \n",
       "4  2018-02-24   9813.07  10287.70  10597.20   9546.97  6917930000   \n",
       "5  2018-02-23  10301.10   9937.07  10487.30   9734.56  7739500000   \n",
       "6  2018-02-22  10005.00  10660.40  11039.10   9939.09  8040080000   \n",
       "7  2018-02-21  10690.40  11372.20  11418.50  10479.10  9405340000   \n",
       "\n",
       "     Market Cap  Sentiment  \n",
       "0  180510000000   0.070307  \n",
       "1  175536000000   0.059455  \n",
       "2  163283000000   0.059455  \n",
       "3  165407000000   0.059455  \n",
       "4  173682000000   0.059455  \n",
       "5  167746000000   0.059455  \n",
       "6  179936000000   0.059455  \n",
       "7  191927000000   0.110849  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe=pd.read_csv('merged_price_sentiment.csv')\n",
    "dataframe.drop(\"Unnamed: 0\",axis=1,inplace=True)\n",
    "dataframe[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframe.drop(['Date'],inplace=True,axis=1)\n",
    "#print(dataframe.head())\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns=dataframe.columns\n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\t\"\"\"\n",
    "\tFrame a time series as a supervised learning dataset.\n",
    "\tArguments:\n",
    "\t\tdata: Sequence of observations as a list or NumPy array.\n",
    "\t\tn_in: Number of lag observations as input (X).\n",
    "\t\tn_out: Number of observations as output (y).\n",
    "\t\tdropnan: Boolean whether or not to drop rows with NaN values.\n",
    "\tReturns:\n",
    "\t\tPandas DataFrame of series framed for supervised learning.\n",
    "\t\"\"\"\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = pd.DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tnames += [(j) for j in columns]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [(\"output \"+j) for j in columns]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = pd.concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created a function which can convert the simple data into time-series data, where the outpu ot future result is of tommorw's data and the input will be today's data. The fucntion is pretty much simple to use. But before using it we are normalizing the data. As we know that normalizing data is neccessary before feeding the data to AI model. We have used Scikit-Learn to do this preprocessing of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Close      Open      High       Low    Volume  Market Cap  Sentiment  \\\n",
      "0  0.541059  0.524411  0.532558  0.530614  0.291347    0.529903   0.178618   \n",
      "1  0.522282  0.486473  0.512080  0.490582  0.304849    0.491656   0.178618   \n",
      "2  0.485554  0.493123  0.484077  0.485491  0.238465    0.498286   0.178618   \n",
      "3  0.493316  0.518850  0.518282  0.493015  0.289321    0.524116   0.178618   \n",
      "4  0.518849  0.500488  0.512704  0.503104  0.323822    0.505587   0.178618   \n",
      "\n",
      "   output Close  \n",
      "0      0.523914  \n",
      "1      0.541059  \n",
      "2      0.522282  \n",
      "3      0.485554  \n",
      "4      0.493316  \n"
     ]
    }
   ],
   "source": [
    "reframed = series_to_supervised(scaled, 1, 1)\n",
    "#print(dataframe.shape)\n",
    "reframed.drop(reframed.columns[[8,9,10,11,12,13]], axis=1, inplace=True)\n",
    "print(reframed.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to reshape the data. As LSTM model,which we are going to build in next step only accepts input with 3-D shape. We are using numpy to do that. Below you can see the code of it and shape of the data also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(541, 1, 7) (541,) (197, 1, 7) (197,)\n"
     ]
    }
   ],
   "source": [
    "values=reframed.values\n",
    "train = values[9:550, :]\n",
    "test = values[550:, :]\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now as we have data and it is reshaped as well as well normalized we can feed it to LSTM model for training and future predictions. To create model we are using Keras framework as it is most easy to use and very much user friednly. Below is the code to create simple LSTM model in keras. Our model has 80 neurons and finally only one output unit as we just want to predict the prices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 541 samples, validate on 197 samples\n",
      "Epoch 1/50\n",
      " - 1s - loss: 0.1806 - val_loss: 0.0552\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.1369 - val_loss: 0.0571\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.1071 - val_loss: 0.0485\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.0759 - val_loss: 0.0302\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.0431 - val_loss: 0.0075\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.0201 - val_loss: 0.0073\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.0214 - val_loss: 0.0073\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.0160 - val_loss: 0.0024\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.0160 - val_loss: 0.0021\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.0151 - val_loss: 0.0017\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.0147 - val_loss: 0.0014\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0014\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.0130 - val_loss: 0.0013\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.0141 - val_loss: 0.0050\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.0138 - val_loss: 0.0023\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0013\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.0123 - val_loss: 0.0013\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.0118 - val_loss: 6.4864e-04\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.0121 - val_loss: 0.0018\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.0125 - val_loss: 6.3058e-04\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.0124 - val_loss: 0.0018\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.0120 - val_loss: 0.0027\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.0137 - val_loss: 0.0014\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.0120 - val_loss: 0.0014\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.0130 - val_loss: 0.0014\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.0123 - val_loss: 8.7945e-04\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.0136 - val_loss: 0.0032\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.0124 - val_loss: 0.0022\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.0121 - val_loss: 0.0012\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.0123 - val_loss: 9.5897e-04\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.0126 - val_loss: 0.0014\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.0138 - val_loss: 0.0034\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.0120 - val_loss: 0.0014\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.0117 - val_loss: 0.0013\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.0122 - val_loss: 9.4299e-04\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0027\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.0129 - val_loss: 0.0014\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.0121 - val_loss: 0.0013\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.0142 - val_loss: 0.0033\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.0126 - val_loss: 0.0034\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.0119 - val_loss: 0.0011\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.0131 - val_loss: 0.0014\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.0133 - val_loss: 8.5926e-04\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.0124 - val_loss: 9.3961e-04\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.0164 - val_loss: 0.0026\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.0122 - val_loss: 7.1801e-04\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.0120 - val_loss: 0.0020\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.0117 - val_loss: 0.0021\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.0156 - val_loss: 0.0038\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.0123 - val_loss: 0.0022\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21dc8e26978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation, Dense\n",
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(80, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=32, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train_loss')\n",
    "pyplot.plot(history.history['val_loss'], label='test_loss')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above plot we can see the errors getting close to each other and close to zero also. This shows that our model is converging well and the loss fucntion is being reduced over the time. As we can see that the model get saturated in terms of reducing the cost after 10 epochs. So training it for more epochs is not useful to as now. We can stop before that but just to see how we are performing over longer run we are running it for 50 epochs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how model performs on testing dataset. We are using mean square error to test the model predictions on test data. We should have nice small floating number to give us idea that how our model has performed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 45.785\n"
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = np.concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = np.concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse =sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_data=np.array([[10725.60,10393.90,10878.50,10246.10,6966180000,175536000000,0.059455],\n",
    "                      [10366.70,9669.43,10475.00,9501.73,7287690000,163283000000,0.059455],\n",
    "                      [9664.73,9796.42,9923.22,9407.06,5706940000,165407000000,0.059455],\n",
    "                      [9813.07,10287.70,10597.20,9546.97,6917930000,173682000000,0.059455],\n",
    "                      [10301.10,9937.07,10487.30,9734.56,7739500000,167746000000,0.059455],\n",
    "                      [10005.00,10660.40,11039.10,9939.09,8040080000,179936000000,0.059455]])\n",
    "#print(predict_data.shape)\n",
    "c=scaler.fit_transform(predict_data)\n",
    "pre=model.predict(c.reshape(predict_data.shape[0],1,predict_data.shape[1]))\n",
    "phat=np.concatenate((pre,c[:,1:]),axis=1)\n",
    "#print(phat)\n",
    "predicted=scaler.inverse_transform(phat)\n",
    "#print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date  Real_close  Predicted_close\n",
      "0 2018-02-28    10397.90     10575.508335\n",
      "1 2018-02-27    10725.60      9968.105953\n",
      "2 2018-02-26    10366.70      9713.071282\n",
      "3 2018-02-25     9664.73     10096.263305\n",
      "4 2018-02-24     9813.07     10128.082514\n",
      "5 2018-02-23    10301.10     10457.213716\n"
     ]
    }
   ],
   "source": [
    "real_close=[10397.90,10725.60,10366.70,9664.73,9813.07,10301.10]\n",
    "predicted_close=[]\n",
    "date=[]\n",
    "difference=[]\n",
    "pr_change=[]\n",
    "date=pd.date_range('2-23-2018','2-28-2018',freq='D').sort_values(ascending=False)\n",
    "#print(date)\n",
    "for i in range(predicted.shape[0]):\n",
    "    predicted_close.append(predicted[i,0])\n",
    "    difference.append(abs(predicted[i,0]-real_close[i]))\n",
    "    pr_change.append((abs(predicted[i,0]-real_close[i])/predicted[i,0])*100)\n",
    "#print(date)\n",
    "df2=pd.DataFrame({'Date':date})\n",
    "#print(len(df2))\n",
    "df2['Real_close']=real_close\n",
    "df2['Predicted_close']=predicted_close\n",
    "#df2['Difference']=difference\n",
    "#df2['Percentage_change']=pr_change\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above predictions are made by our LSTM model which is trained on numeric as well as sentiment score. If we see its performance then it is good. Not much improved but not bad also. We can imrpove upon it by using ensembling methods. But for that we should have large data which is quite not possible as Bitcoins are just for 7 years in market. Also geting tweets from twitter API is not free if you want to have data for long time like years or so. So we have this nice simple LSTM model which can predict the prices of Bitcoin close to the original one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date  Real Close  Model_numeric_data  Model_numeric _data+Sentiments\n",
      "0 2018-02-28    10397.90        10491.695183                    10575.508335\n",
      "1 2018-02-27    10725.60         9997.942656                     9968.105953\n",
      "2 2018-02-26    10366.70         9703.386253                     9713.071282\n",
      "3 2018-02-25     9664.73        10050.264651                    10096.263305\n",
      "4 2018-02-24     9813.07        10110.501936                    10128.082514\n",
      "5 2018-02-23    10301.10        10349.661903                    10457.213716\n"
     ]
    }
   ],
   "source": [
    "combined=df.merge(df2,on='Date',how='inner')\n",
    "combined.rename(columns={'real_close':'Real Close','predicted_close':'Model_numeric_data',\n",
    "                        'Predicted_close':'Model_numeric _data+Sentiments'},inplace=True)\n",
    "combined.drop(['Real_close','Difference','Percentage_change'],inplace=True,axis=1)\n",
    "print(combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above comparision we can see the real close prices, predicted prices only with numeric data and predicted prices with sentiment socre and numeric data. The prices are not much different. They are almost the same as expected. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
